{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 17:34:35.500964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/yeting/.mujoco/mujoco210/bin\n",
      "2022-09-29 17:34:35.501043: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 12s 1us/step\n",
      "11501568/11490434 [==============================] - 12s 1us/step\n",
      "datasets: (60000, 28, 28) (60000,) 0 255\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    x is a simple image, not a batch\n",
    "    \"\"\"\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分验证集\n",
    "通过验证集来调整学习率，权值衰减系数、训练次数等\n",
    "判断当前是否为过拟合或欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 17:35:27.553550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/yeting/.mujoco/mujoco210/bin\n",
      "2022-09-29 17:35:27.553638: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-29 17:35:27.553748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 194e736ac838\n",
      "2022-09-29 17:35:27.553779: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 194e736ac838\n",
      "2022-09-29 17:35:27.553929: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-09-29 17:35:27.554041: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\n",
      "2022-09-29 17:35:27.563793: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,) (10000, 28, 28) (10000,)\n",
      "(128, 784) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "idx = tf.range(60000)\n",
    "idx = tf.random.shuffle(idx)\n",
    "x_train, y_train = tf.gather(x, idx[:50000]), tf.gather(y, idx[:50000])\n",
    "x_val, y_val = tf.gather(x, idx[-10000:]), tf.gather(y, idx[-10000:])\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.map(preprocess).shuffle(50000).batch(batchsz)\n",
    "\n",
    "db_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "db_val = db_val.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.map(preprocess).batch(batchsz)\n",
    "\n",
    "sample = next(iter(db_train))\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeting/.local/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 5s 6ms/step - loss: 0.2905 - accuracy: 0.9120\n",
      "Epoch 2/6\n",
      "391/391 [==============================] - 4s 7ms/step - loss: 0.1398 - accuracy: 0.9617 - val_loss: 0.1762 - val_accuracy: 0.9508\n",
      "Epoch 3/6\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.1129 - accuracy: 0.9692\n",
      "Epoch 4/6\n",
      "391/391 [==============================] - 4s 8ms/step - loss: 0.1046 - accuracy: 0.9720 - val_loss: 0.1534 - val_accuracy: 0.9611\n",
      "Epoch 5/6\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0864 - accuracy: 0.9759\n",
      "Epoch 6/6\n",
      "391/391 [==============================] - 4s 7ms/step - loss: 0.0803 - accuracy: 0.9779 - val_loss: 0.1686 - val_accuracy: 0.9608\n",
      "Test performance:\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12381090968847275, 0.9697999954223633]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.compile(optimizer=optimizers.Adam(learning_rate==0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "network.fit(db_train, epochs=6, validation_data=db_val, validation_freq=2)\n",
    "\n",
    "print('Test performance:')\n",
    "network.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 5 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 9 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 4 7 6 7 4 0 5], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(db_test))\n",
    "x = sample[0]\n",
    "y = sample[1]  # one-hot\n",
    "pred = network.predict(x)  # [b, 10]\n",
    "# convert back to number\n",
    "y = tf.argmax(y, axis=1)\n",
    "pred = tf.argmax(pred, axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
